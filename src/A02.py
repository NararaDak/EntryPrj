import torch
from torch.utils.data import Dataset
from PIL import Image
import json
import os
from torchvision import transforms
import torchvision.models as models
import torch.nn as nn
from efficientnet_pytorch import EfficientNet
import datetime
import sys
from filelock import FileLock
import matplotlib.pyplot as plt
import torch.optim as optim
from ultralytics import YOLO

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# â–£ 0. ë””ë ‰í† ë¦¬ ë° ìœ í‹¸ í•¨ìˆ˜ ì„¤ì • 
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
BASE_DIR = r"D:\01.project\EntryPrj\data"
LOG_FILE = os.path.join(BASE_DIR, "operation.log")
ANNOTATION_DIR = os.path.join(BASE_DIR, "oraldrug", "train_annotations")
TRAIN_IMG_DIR = os.path.join(BASE_DIR, "oraldrug", "train_images")
TEST_IMG_DIR = os.path.join(BASE_DIR, "oraldrug", "test_images")
YAML_FILE   = os.path.join(BASE_DIR, "oraldrug", "yolo_yaml.yaml")
MODEL_FILES = os.path.join(BASE_DIR, "oraldrug", "models")
RESULT_CSV = f"{BASE_DIR}/entryprj.csv"
DEVICE_TYPE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

## êµ¬ë¶„ì„  ì¶œë ¥ í•¨ìˆ˜
def Lines(text="", count=100):
    print("â•" * count)
    if text != "":
        print(f"{text}")
        print("â•" * count)
## í˜„ì¬ ì‹œê°„ ë¬¸ìì—´ ë°˜í™˜ í•¨ìˆ˜
def now_str():
    return datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
## ë””ë ‰í† ë¦¬ ìƒì„± í•¨ìˆ˜
def makedirs(d):
    os.makedirs(d, exist_ok=True)
## ìš´ì˜ ë¡œê·¸ í•¨ìˆ˜
def OpLog(log, bLines=True):
    if bLines:
        Lines(f"[{now_str()}] {log}")
    try:
        caller_name = sys._getframe(1).f_code.co_name
    except Exception:
        caller_name = "UnknownFunction"
        
    log_filename = LOG_FILE
    log_lock_filename = log_filename + ".lock"
    log_content = f"[{now_str()}] {caller_name}: {log}\n"
    try:
        lock = FileLock(log_lock_filename, timeout=10)
        with lock:
            with open(log_filename, 'a', encoding='utf-8') as f:
                f.write(log_content)
    except Exception as e:
        print(f"Log write error: {e}")
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# â–£ 1. í´ë˜ìŠ¤ ìˆ˜ ê³„ì‚°
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# train_annotationsì—ì„œ ê³ ìœ í•œ K-* ë””ë ‰í† ë¦¬ ê°œìˆ˜ë¡œ í´ë˜ìŠ¤ ìˆ˜ ê³„ì‚°
def count_classes(annotations_dir):
    unique_classes = set()
    for subdir in os.listdir(annotations_dir):
        subdir_path = os.path.join(annotations_dir, subdir)
        if os.path.isdir(subdir_path):
            for class_dir in os.listdir(subdir_path):
                if class_dir.startswith('K-'):
                    unique_classes.add(class_dir)
    return len(unique_classes)

Lines(f"ANNOTATION_DIR: {ANNOTATION_DIR}")
num_classes = count_classes(ANNOTATION_DIR)
OpLog(f"ì´ í´ë˜ìŠ¤ ìˆ˜: {num_classes}", bLines=True)
 
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# â–£ 2. ë°ì´í„°ì…‹ ë° ë°ì´í„° ì¦ê°• í•¨ìˆ˜ ì •ì˜
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ë‹¤ì–‘í•œ ë°ì´í„° ì¦ê°•(transform) í•¨ìˆ˜ ì •ì˜
def GetTransform(transform_type="default"):
    if( transform_type == "default" ):
        return transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
        ])
    if( transform_type == "A" ):
        return transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.2, hue=0.1),
            transforms.RandomRotation(degrees=15),
            transforms.ToTensor(),
        ])
    elif( transform_type == "B" ):
        return transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.RandomAffine(degrees=10, translate=(0.1, 0.1), scale=(0.9, 1.1)),
            transforms.GaussianBlur(kernel_size=(5, 5), sigma=(0.1, 2.0)),
            transforms.ToTensor(),
        ])
    else:
        return transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
        ])

# ì»¤ìŠ¤í…€ ë°ì´í„°ì…‹ í´ë˜ìŠ¤ ì •ì˜
class PillDataset(Dataset):
    def __init__(self, annotations_dir, img_dir, transform=None):
        """ annotations_dir: train_annotations ê²½ë¡œ
        img_dir: train_images ê²½ë¡œ
        """
        self.img_dir = img_dir
        self.transform = transform
        self.samples = []  # (img_path, label_idx, class_name) íŠœí”Œ ë¦¬ìŠ¤íŠ¸
        self.class_to_idx = {}  # {class_name: idx}
        self.idx_to_class = {}  # {idx: class_name}
        
        # ëª¨ë“  í´ë˜ìŠ¤(K-*) ë””ë ‰í† ë¦¬ ìˆ˜ì§‘
        class_dirs = []
        for subdir in os.listdir(annotations_dir):
            subdir_path = os.path.join(annotations_dir, subdir)
            if os.path.isdir(subdir_path):
                for class_dir in os.listdir(subdir_path):
                    if class_dir.startswith('K-'):
                        class_dir_path = os.path.join(subdir_path, class_dir)
                        if os.path.isdir(class_dir_path):
                            class_dirs.append((class_dir, class_dir_path))
        
        # í´ë˜ìŠ¤ ì •ë ¬ ë° ì¸ë±ìŠ¤ ë§¤í•‘
        self._unique_classes = sorted(set([cls for cls, _ in class_dirs]))
        self.class_to_idx = {cls: idx for idx, cls in enumerate(self._unique_classes)}
        self.idx_to_class = {idx: cls for cls, idx in self.class_to_idx.items()}
        
        # ê° í´ë˜ìŠ¤ì˜ annotation íŒŒì¼ ì½ê¸°
        for class_name, class_dir_path in class_dirs:
            label_idx = self.class_to_idx[class_name]
            
            # í´ë˜ìŠ¤ ë””ë ‰í† ë¦¬ ë‚´ ëª¨ë“  JSON íŒŒì¼ ì½ê¸°
            for json_file in os.listdir(class_dir_path):
                if json_file.endswith('.json'):
                    json_path = os.path.join(class_dir_path, json_file)
                    try:
                        with open(json_path, 'r', encoding='utf-8') as f:
                            data = json.load(f)
                        
                        # images ì •ë³´ ì¶”ì¶œ
                        if 'images' in data:
                            for img_info in data['images']:
                                img_filename = img_info['file_name']
                                img_path = os.path.join(self.img_dir, img_filename)
                                
                                # ì´ë¯¸ì§€ íŒŒì¼ì´ ì‹¤ì œë¡œ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
                                if os.path.exists(img_path):
                                    self.samples.append((img_path, label_idx, class_name))
                    except Exception as e:
                        OpLog(f"Error reading {json_path}: {e}", bLines=False)

    def __len__(self):
        return len(self.samples)

    def __getitem__(self, idx):
        img_path, label, class_name = self.samples[idx]
        image = Image.open(img_path).convert("RGB")

        if self.transform:
            image = self.transform(image)
        return image, label

def GetDataset(annotations_dir, img_dir, transform_type="default"):
    transform = GetTransform(transform_type)
    dataset = PillDataset(annotations_dir, img_dir, transform)
    return dataset

def GetLoaders(annotations_dir, img_dir, batch_size=32, train_ratio=0.8, num_workers=4):
    """
    ì „ì²´ ë°ì´í„°ì…‹ì„ train/valë¡œ ë¶„í• í•˜ì—¬ DataLoader ìƒì„±
    """
    from torch.utils.data import DataLoader, random_split
    
    # ì „ì²´ ë°ì´í„°ì…‹ ë¡œë“œ (trainìš© augmentation)
    full_dataset = GetDataset(annotations_dir, img_dir, transform_type="A")
    # Train/Val ë¶„í• 
    total_size = len(full_dataset)
    train_size = int(total_size * train_ratio)
    val_size = total_size - train_size
    train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])
    # Validation ë°ì´í„°ì…‹ì—ëŠ” augmentation ì—†ì´ ê¸°ë³¸ transformë§Œ ì ìš©
    val_dataset_plain = GetDataset(annotations_dir, img_dir, transform_type="default")
    val_indices = val_dataset.indices
    val_dataset = torch.utils.data.Subset(val_dataset_plain, val_indices)
    # DataLoader ìƒì„±
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)
    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)
    OpLog(f"Train samples: {len(train_dataset)}, Val samples: {len(val_dataset)}", bLines=False)
    OpLog(f"Total classes: {len(full_dataset.class_to_idx)}", bLines=False)
    return train_loader, val_loader

def TestLoader():
    train_loader, val_loader = GetLoaders(ANNOTATION_DIR, TRAIN_IMG_DIR, batch_size=16, train_ratio=0.8, num_workers=2)
    return train_loader, val_loader
TestLoader()


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# â–£ 3. ê¸°ë³¸ ëª¨ë¸ í´ë˜ìŠ¤ ì •ì˜ 
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class BaseModel(nn.Module):
    """ëª¨ë¸ì˜ ê¸°ë³¸ í´ë˜ìŠ¤ - save/load ë“± ê³µí†µ ê¸°ëŠ¥ ì œê³µ"""
    def __init__(self):
        super(BaseModel, self).__init__()
    
    ## ëª¨ë¸ ì €ì¥ í•¨ìˆ˜
    def save_model(self, epoch_index, is_best=False, **kwargs):
        """í˜„ì¬ ëª¨ë¸ ìƒíƒœë¥¼ ì €ì¥
        
        Args:
            epoch_index: í˜„ì¬ ì—í¬í¬ ë²ˆí˜¸
            is_best: Best ëª¨ë¸ì¸ì§€ ì—¬ë¶€
            **kwargs: ì¶”ê°€ë¡œ ì €ì¥í•  ë°ì´í„° (model_state_dict, train_losses ë“±)
        """
        save_dir = MODEL_FILES
        makedirs(save_dir)
        model_name = self.__class__.__name__
        
        # Best ëª¨ë¸ íŒŒì¼ëª…
        if is_best:
            filename = os.path.join(save_dir, f"{model_name}_best_model.pth")
        else:
            filename = os.path.join(save_dir, f"{model_name}_epoch_{epoch_index}.pth")
        
        # ê¸°ë³¸ ì €ì¥ ë°ì´í„°
        checkpoint = {
            'epoch': epoch_index,
            'is_best': is_best,
            'model_name': model_name,
        }
        
        # kwargsë¡œ ì „ë‹¬ëœ ì¶”ê°€ ë°ì´í„° ì €ì¥
        checkpoint.update(kwargs)
        
        torch.save(checkpoint, filename)
        
        if is_best:
            print(f"  ğŸ† Best ëª¨ë¸ ì €ì¥ë¨: {filename}")
            OpLog(f"Best model saved: {filename}")
        else:
            OpLog(f"ëª¨ë¸ ì €ì¥ë¨: {filename}", bLines=False)

    ## ëª¨ë¸ ë¡œë“œ í•¨ìˆ˜
    def load_model(self, model_file, **kwargs):
        """ì €ì¥ëœ ëª¨ë¸ ìƒíƒœë¥¼ ë¡œë“œ
        
        Args:
            model_file: ëª¨ë¸ íŒŒì¼ ê²½ë¡œ
            **kwargs: ë¡œë“œ ê´€ë ¨ ì¶”ê°€ ì˜µì…˜
            
        Returns:
            dict: ì²´í¬í¬ì¸íŠ¸ ë°ì´í„° ë˜ëŠ” None
        """
        if not os.path.exists(model_file):
            OpLog(f"ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model_file}", bLines=True)
            return None
        
        checkpoint = torch.load(model_file, map_location=DEVICE_TYPE)
        
        OpLog(f"ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {model_file} (Epoch {checkpoint['epoch']})", bLines=True)
        return checkpoint

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# â–£ 4. EfficientNetModel ëª¨ë¸ ì •ì˜ 
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

   
class EfficientNetModel(BaseModel):
    """
    ì•Œì•½ ë¶„ë¥˜ ëª¨ë¸ (ì´ë¯¸ì§€ ë¶„ë¥˜ìš©)
    ì£¼ì˜: ì‹¤ì œ YOLO ê°ì²´ íƒì§€ ëª¨ë¸ì´ ì•„ë‹Œ EfficientNet ê¸°ë°˜ ë¶„ë¥˜ê¸°ì…ë‹ˆë‹¤.
    """
    def __init__(self, num_classes):
        super(EfficientNetModel, self).__init__()
        self.num_classes = num_classes
        # EfficientNet-B0 ëª¨ë¸ ë¡œë“œ (ì‚¬ì „ í•™ìŠµëœ ê°€ì¤‘ì¹˜ ì‚¬ìš©)
        self.backbone = EfficientNet.from_pretrained('efficientnet-b0')
        # ë¶„ë¥˜ê¸° ë ˆì´ì–´ êµì²´
        in_features = self.backbone._fc.in_features
        self.backbone._fc = nn.Linear(in_features, num_classes)
        
        # í•™ìŠµ ì´ë ¥ ì €ì¥ìš©
        self.train_losses = []
        self.train_accs = []
        self.val_accs = []
    @staticmethod
    def preJob():
        """ì „ì²˜ë¦¬ ì‘ì—…: YOLO YAML íŒŒì¼ ë° í´ë˜ìŠ¤ ë§¤í•‘ ìƒì„± (ì—†ì„ ê²½ìš°ì—ë§Œ)"""
        import yaml
        
        class_mapping_file = os.path.join(BASE_DIR, "oraldrug", "class_mapping.json")
        
        # YAML íŒŒì¼ì´ ì´ë¯¸ ì¡´ì¬í•˜ë©´ íŒ¨ìŠ¤
        if os.path.exists(YAML_FILE):
            OpLog(f"YAML íŒŒì¼ì´ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤: {YAML_FILE}", bLines=False)
            return
        
        OpLog("YOLO YAML íŒŒì¼ ìƒì„± ì‹œì‘", bLines=True)
        
        # ëª¨ë“  í´ë˜ìŠ¤(K-*) ìˆ˜ì§‘ ë° dl_name ë§¤í•‘
        class_to_name = {}  # {K-code: dl_name}
        unique_classes = set()
        
        for subdir in os.listdir(ANNOTATION_DIR):
            subdir_path = os.path.join(ANNOTATION_DIR, subdir)
            if os.path.isdir(subdir_path):
                for class_dir in os.listdir(subdir_path):
                    if class_dir.startswith('K-'):
                        unique_classes.add(class_dir)
                        
                        # í•´ë‹¹ í´ë˜ìŠ¤ í´ë”ì˜ ì²« ë²ˆì§¸ JSON íŒŒì¼ì—ì„œ dl_name ì¶”ì¶œ
                        class_dir_path = os.path.join(subdir_path, class_dir)
                        if os.path.isdir(class_dir_path) and class_dir not in class_to_name:
                            for json_file in os.listdir(class_dir_path):
                                if json_file.endswith('.json'):
                                    json_path = os.path.join(class_dir_path, json_file)
                                    try:
                                        with open(json_path, 'r', encoding='utf-8') as f:
                                            data = json.load(f)
                                        if 'images' in data and len(data['images']) > 0:
                                            dl_name = data['images'][0].get('dl_name', class_dir)
                                            class_to_name[class_dir] = dl_name
                                            break
                                    except Exception as e:
                                        OpLog(f"Error reading {json_path}: {e}", bLines=False)
        
        # í´ë˜ìŠ¤ ì •ë ¬
        class_names = sorted(unique_classes)
        
        # í´ë˜ìŠ¤ ë§¤í•‘ ì •ë³´ ì €ì¥ (K-code: {index, dl_name})
        class_mapping = {}
        for idx, cls in enumerate(class_names):
            class_mapping[cls] = {
                'index': idx,
                'dl_name': class_to_name.get(cls, cls)
            }
        
        # í´ë˜ìŠ¤ ë§¤í•‘ JSON íŒŒì¼ ì €ì¥
        with open(class_mapping_file, 'w', encoding='utf-8') as f:
            json.dump(class_mapping, f, ensure_ascii=False, indent=2)
        
        # YAML ë°ì´í„° êµ¬ì¡° ìƒì„±
        yaml_data = {
            'path': BASE_DIR,
            'train': 'oraldrug/train_images',
            'val': 'oraldrug/val_images',
            'test': 'oraldrug/test_images',
            'nc': len(class_names),
            'names': class_names
        }
        
        # YAML íŒŒì¼ ì €ì¥
        makedirs(os.path.dirname(YAML_FILE))
        with open(YAML_FILE, 'w', encoding='utf-8') as f:
            yaml.dump(yaml_data, f, default_flow_style=False, allow_unicode=True, sort_keys=False)
        
        OpLog(f"YAML íŒŒì¼ ìƒì„± ì™„ë£Œ: {YAML_FILE}", bLines=False)
        OpLog(f"í´ë˜ìŠ¤ ë§¤í•‘ íŒŒì¼ ìƒì„± ì™„ë£Œ: {class_mapping_file}", bLines=False)
        OpLog(f"ì´ í´ë˜ìŠ¤ ìˆ˜: {len(class_names)}", bLines=False)
        
    def forward(self, x):
        return self.backbone(x)

    def getOptimizers(self, lr, betas):
        optimizer = torch.optim.Adam(self.parameters(), lr=lr, betas=betas)
        return optimizer
    def getCriterion(self):
        criterion = nn.CrossEntropyLoss()
        return criterion


    def fit(self, train_loader, val_loader, epochs=50, lr=0.0002, device='cuda'):
        """
        í˜„ì¬ êµ¬í˜„: ì´ë¯¸ì§€ ë¶„ë¥˜(Classification) í•™ìŠµ
        - EfficientNet ë°±ë³¸ ì‚¬ìš©
        - CrossEntropyLossë¡œ í´ë˜ìŠ¤ ë¶„ë¥˜ë§Œ ìˆ˜í–‰
        - bbox ì •ë³´ëŠ” ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
        
        ì£¼ì˜: ì‹¤ì œ YOLOëŠ” ê°ì²´ íƒì§€ ëª¨ë¸ì´ë©°, bbox ì˜ˆì¸¡ + í´ë˜ìŠ¤ ë¶„ë¥˜ë¥¼ ë™ì‹œì— ìˆ˜í–‰í•©ë‹ˆë‹¤.
        ì§„ì •í•œ YOLO í•™ìŠµì„ ì›í•œë‹¤ë©´ YOLOv5/YOLOv8 ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš©ì„ ê¶Œì¥í•©ë‹ˆë‹¤.
        """
        self.train()
        optimizer = self.getOptimizers(lr, (0.5, 0.999))
        criterion = self.getCriterion()
        
        best_val_acc = 0.0
        
        for epoch in range(epochs):
            epoch_loss = 0.0
            correct = 0
            total = 0
            
            # Training loop
            for batch_idx, (images, labels) in enumerate(train_loader):
                images, labels = images.to(device), labels.to(device)
                
                optimizer.zero_grad()
                outputs = self(images)  # forward ë©”ì„œë“œ í˜¸ì¶œ
                loss = criterion(outputs, labels)
                loss.backward()
                optimizer.step()
                
                epoch_loss += loss.item()
                
                # ì •í™•ë„ ê³„ì‚°
                _, predicted = torch.max(outputs.data, 1)
                total += labels.size(0)
                correct += (predicted == labels).sum().item()
                
                if batch_idx % 10 == 0:
                    OpLog(f"Epoch [{epoch+1}/{epochs}], Batch [{batch_idx}/{len(train_loader)}], "
                          f"Loss: {loss.item():.4f}", bLines=False)
            
            # Epoch ê²°ê³¼ ì¶œë ¥
            avg_loss = epoch_loss / len(train_loader)
            accuracy = 100 * correct / total
            self.train_losses.append(avg_loss)
            self.train_accs.append(accuracy)
            
            OpLog(f"Epoch [{epoch+1}/{epochs}] ì™„ë£Œ - Avg Loss: {avg_loss:.4f}, "
                  f"Train Accuracy: {accuracy:.2f}%", bLines=True)
            
            # Validation
            if val_loader:
                val_acc = self.evaluate(val_loader, device)
                self.val_accs.append(val_acc)
                OpLog(f"Validation Accuracy: {val_acc:.2f}%", bLines=False)
                
                # Best ëª¨ë¸ ì €ì¥
                if val_acc > best_val_acc:
                    best_val_acc = val_acc
                    self.save_model(epoch + 1, is_best=True,
                                  model_state_dict=self.state_dict(),
                                  num_classes=self.num_classes,
                                  train_losses=self.train_losses,
                                  train_accs=self.train_accs,
                                  val_accs=self.val_accs)
                    OpLog(f"Best ëª¨ë¸ ì €ì¥ë¨ (Epoch {epoch+1}, Val Acc: {val_acc:.2f}%)", bLines=False)
            
            # ì£¼ê¸°ì  ì €ì¥ (10 ì—í¬í¬ë§ˆë‹¤)
            if (epoch + 1) % 10 == 0:
                self.save_model(epoch + 1, is_best=False,
                              model_state_dict=self.state_dict(),
                              num_classes=self.num_classes,
                              train_losses=self.train_losses,
                              train_accs=self.train_accs,
                              val_accs=self.val_accs)
        
        # í•™ìŠµ ì™„ë£Œ í›„ ìµœì¢… ëª¨ë¸ ì €ì¥
        self.save_model(epochs, is_best=False,
                       model_state_dict=self.state_dict(),
                       num_classes=self.num_classes,
                       train_losses=self.train_losses,
                       train_accs=self.train_accs,
                       val_accs=self.val_accs)
        OpLog(f"í•™ìŠµ ì™„ë£Œ! Best Validation Accuracy: {best_val_acc:.2f}%", bLines=True)
        
        # í•™ìŠµ ê³¡ì„  ì‹œê°í™”
        self.plot_training_history()
    
    def evaluate(self, val_loader, device='cuda'):
        """ê²€ì¦ ë°ì´í„°ì…‹ì— ëŒ€í•œ ì •í™•ë„ í‰ê°€ (ë¶„ë¥˜ ëª¨ë¸ìš©)"""
        self.eval()
        correct = 0
        total = 0
        all_predictions = []
        all_labels = []
        
        with torch.no_grad():
            for images, labels in val_loader:
                images, labels = images.to(device), labels.to(device)
                outputs = self(images)
                _, predicted = torch.max(outputs.data, 1)
                total += labels.size(0)
                correct += (predicted == labels).sum().item()
                
                all_predictions.extend(predicted.cpu().numpy())
                all_labels.extend(labels.cpu().numpy())
        
        accuracy = 100 * correct / total
        self.train()  # ë‹¤ì‹œ í•™ìŠµ ëª¨ë“œë¡œ ì „í™˜
        return accuracy
    
    def load_yolo_model(self, model_path):
        """YOLO ëª¨ë¸ ì „ìš© ë¡œë“œ í•¨ìˆ˜"""
        checkpoint = self.load_model(model_path)
        if checkpoint is None:
            return False
        
        # YoloModel ì „ìš© ë°ì´í„° ë³µì›
        if 'model_state_dict' in checkpoint:
            self.load_state_dict(checkpoint['model_state_dict'])
        self.train_losses = checkpoint.get('train_losses', [])
        self.train_accs = checkpoint.get('train_accs', [])
        self.val_accs = checkpoint.get('val_accs', [])
        
        return True
    
    def plot_training_history(self):
        """í•™ìŠµ ì´ë ¥ ì‹œê°í™”"""
        if not self.train_losses:
            return
        
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))
        
        # Loss ê·¸ë˜í”„
        ax1.plot(self.train_losses, label='Train Loss')
        ax1.set_xlabel('Epoch')
        ax1.set_ylabel('Loss')
        ax1.set_title('Training Loss')
        ax1.legend()
        ax1.grid(True)
        
        # Accuracy ê·¸ë˜í”„
        ax2.plot(self.train_accs, label='Train Accuracy')
        if self.val_accs:
            ax2.plot(self.val_accs, label='Validation Accuracy')
        ax2.set_xlabel('Epoch')
        ax2.set_ylabel('Accuracy (%)')
        ax2.set_title('Training & Validation Accuracy')
        ax2.legend()
        ax2.grid(True)
        
        plt.tight_layout()
        
        # ì €ì¥
        result_dir = os.path.join(BASE_DIR, "model_results")
        makedirs(result_dir)
        filename = os.path.join(result_dir, "training_history.png")
        plt.savefig(filename, dpi=100, bbox_inches='tight')
        OpLog(f"í•™ìŠµ ì´ë ¥ ê·¸ë˜í”„ ì €ì¥ë¨: {filename}", bLines=False)
        
        plt.show(block=False)
        plt.pause(3)
        plt.close()

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# â–£ 5. YOLOv8 ëª¨ë¸ ì •ì˜ 
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class YOLOv8Model(BaseModel):
    """
    YOLOv8 ê¸°ë°˜ ê°ì²´ íƒì§€ ëª¨ë¸
    - Ultralytics YOLOv8 ì‚¬ìš©
    - ê°ì²´ íƒì§€ ë° ë¶„ë¥˜ ë™ì‹œ ìˆ˜í–‰
    """
    def __init__(self, model_size='n', num_classes=None):
        """
        Args:
            model_size: YOLOv8 ëª¨ë¸ í¬ê¸° ('n', 's', 'm', 'l', 'x')
            num_classes: í´ë˜ìŠ¤ ìˆ˜ (Noneì´ë©´ ìë™ ê³„ì‚°)
        """
        super(YOLOv8Model, self).__init__()
        self.model_size = model_size
        self.num_classes = num_classes if num_classes else count_classes(ANNOTATION_DIR)
        
        # YOLOv8 ëª¨ë¸ ì´ˆê¸°í™” (ì‚¬ì „ í•™ìŠµëœ ê°€ì¤‘ì¹˜ ì‚¬ìš©)
        self.model = YOLO(f'yolov8{model_size}.pt')
        
        # í•™ìŠµ ì´ë ¥ ì €ì¥ìš©
        self.train_losses = []
        self.val_metrics = []
    
    @staticmethod
    def preJob():
        """ì „ì²˜ë¦¬ ì‘ì—…: YOLO YAML íŒŒì¼ ë° í´ë˜ìŠ¤ ë§¤í•‘ ìƒì„± (ì—†ì„ ê²½ìš°ì—ë§Œ)"""
        import yaml
        
        class_mapping_file = os.path.join(BASE_DIR, "oraldrug", "class_mapping.json")
        
        # YAML íŒŒì¼ì´ ì´ë¯¸ ì¡´ì¬í•˜ë©´ íŒ¨ìŠ¤
        if os.path.exists(YAML_FILE):
            OpLog(f"YAML íŒŒì¼ì´ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤: {YAML_FILE}", bLines=False)
            return
        
        OpLog("YOLO YAML íŒŒì¼ ìƒì„± ì‹œì‘", bLines=True)
        
        # ëª¨ë“  í´ë˜ìŠ¤(K-*) ìˆ˜ì§‘ ë° dl_name ë§¤í•‘
        class_to_name = {}  # {K-code: dl_name}
        unique_classes = set()
        
        for subdir in os.listdir(ANNOTATION_DIR):
            subdir_path = os.path.join(ANNOTATION_DIR, subdir)
            if os.path.isdir(subdir_path):
                for class_dir in os.listdir(subdir_path):
                    if class_dir.startswith('K-'):
                        unique_classes.add(class_dir)
                        
                        # í•´ë‹¹ í´ë˜ìŠ¤ í´ë”ì˜ ì²« ë²ˆì§¸ JSON íŒŒì¼ì—ì„œ dl_name ì¶”ì¶œ
                        class_dir_path = os.path.join(subdir_path, class_dir)
                        if os.path.isdir(class_dir_path) and class_dir not in class_to_name:
                            for json_file in os.listdir(class_dir_path):
                                if json_file.endswith('.json'):
                                    json_path = os.path.join(class_dir_path, json_file)
                                    try:
                                        with open(json_path, 'r', encoding='utf-8') as f:
                                            data = json.load(f)
                                        if 'images' in data and len(data['images']) > 0:
                                            dl_name = data['images'][0].get('dl_name', class_dir)
                                            class_to_name[class_dir] = dl_name
                                            break
                                    except Exception as e:
                                        OpLog(f"Error reading {json_path}: {e}", bLines=False)
        
        # í´ë˜ìŠ¤ ì •ë ¬
        class_names = sorted(unique_classes)
        
        # í´ë˜ìŠ¤ ë§¤í•‘ ì •ë³´ ì €ì¥ (K-code: {index, dl_name})
        class_mapping = {}
        for idx, cls in enumerate(class_names):
            class_mapping[cls] = {
                'index': idx,
                'dl_name': class_to_name.get(cls, cls)
            }
        
        # í´ë˜ìŠ¤ ë§¤í•‘ JSON íŒŒì¼ ì €ì¥
        with open(class_mapping_file, 'w', encoding='utf-8') as f:
            json.dump(class_mapping, f, ensure_ascii=False, indent=2)
        
        # YAML ë°ì´í„° êµ¬ì¡° ìƒì„±
        yaml_data = {
            'path': BASE_DIR,
            'train': 'oraldrug/train_images',
            'val': 'oraldrug/val_images',
            'test': 'oraldrug/test_images',
            'nc': len(class_names),
            'names': class_names
        }
        
        # YAML íŒŒì¼ ì €ì¥
        makedirs(os.path.dirname(YAML_FILE))
        with open(YAML_FILE, 'w', encoding='utf-8') as f:
            yaml.dump(yaml_data, f, default_flow_style=False, allow_unicode=True, sort_keys=False)
        
        OpLog(f"YAML íŒŒì¼ ìƒì„± ì™„ë£Œ: {YAML_FILE}", bLines=False)
        OpLog(f"í´ë˜ìŠ¤ ë§¤í•‘ íŒŒì¼ ìƒì„± ì™„ë£Œ: {class_mapping_file}", bLines=False)
        OpLog(f"ì´ í´ë˜ìŠ¤ ìˆ˜: {len(class_names)}", bLines=False)
    
    def fit(self, epochs=50, imgsz=640, batch_size=16, device='cuda'):
        """
        YOLOv8 ëª¨ë¸ í•™ìŠµ (BaseModel save_model ì‚¬ìš©)
        
        Args:
            epochs: í•™ìŠµ ì—í¬í¬ ìˆ˜
            imgsz: ì…ë ¥ ì´ë¯¸ì§€ í¬ê¸°
            batch_size: ë°°ì¹˜ í¬ê¸°
            device: 'cuda' ë˜ëŠ” 'cpu'
        """
        from ultralytics.utils.callbacks import default_callbacks
        
        OpLog(f"YOLOv8{self.model_size} ëª¨ë¸ í•™ìŠµ ì‹œì‘", bLines=True)
        
        # YAML íŒŒì¼ í™•ì¸
        if not os.path.exists(YAML_FILE):
            self.preJob()
        
        # ë§¤ epochë§ˆë‹¤ BaseModelì˜ save_modelì„ í˜¸ì¶œí•˜ëŠ” ì½œë°± í•¨ìˆ˜
        def on_epoch_end(trainer):
            epoch = trainer.epoch
            # BaseModelì˜ save_model ì‚¬ìš©
            save_path = os.path.join(MODEL_DIR, f"yolov8{self.model_size}_epoch{epoch+1}.pt")
            self.save_model(
                filepath=save_path,
                epoch=epoch + 1,
                model_state=trainer.model.state_dict(),
                metrics={
                    'box_loss': float(trainer.loss_items[0]) if trainer.loss_items is not None else 0,
                    'cls_loss': float(trainer.loss_items[1]) if trainer.loss_items is not None else 0,
                    'dfl_loss': float(trainer.loss_items[2]) if trainer.loss_items is not None else 0,
                }
            )
            OpLog(f"Epoch {epoch+1} ëª¨ë¸ ì €ì¥: {save_path}", bLines=False)
        
        # ì½œë°± ì¶”ê°€
        self.model.add_callback("on_epoch_end", on_epoch_end)
        
        # YOLOv8 í•™ìŠµ ì‹œì‘
        results = self.model.train(
            data=YAML_FILE,
            epochs=epochs,
            imgsz=imgsz,
            batch=batch_size,
            device=device,
            project=os.path.join(BASE_DIR, "yolo_results"),
            name=f"yolov8{self.model_size}_train",
            exist_ok=True,
            patience=10,  # Early stopping
            save=True,  # ìµœì¢… ëª¨ë¸ ì €ì¥
            plots=True,
            verbose=True,
        )
        
        OpLog(f"YOLOv8 í•™ìŠµ ì™„ë£Œ!", bLines=True)
        
        # í•™ìŠµ ê²°ê³¼ ì‹œê°í™”
        self.plot_results()
        
        return results
    
    def evaluate(self, data_yaml=None, device='cuda'):
        """
        ê²€ì¦ ë°ì´í„°ì…‹ì— ëŒ€í•œ ëª¨ë¸ í‰ê°€
        
        Args:
            data_yaml: ë°ì´í„°ì…‹ YAML íŒŒì¼ ê²½ë¡œ (Noneì´ë©´ YAML_FILE ì‚¬ìš©)
            device: 'cuda' ë˜ëŠ” 'cpu'
        """
        if data_yaml is None:
            data_yaml = YAML_FILE
        
        OpLog("YOLOv8 ëª¨ë¸ í‰ê°€ ì‹œì‘", bLines=True)
        
        # ëª¨ë¸ ê²€ì¦
        metrics = self.model.val(
            data=data_yaml,
            device=device,
            split='val',
            plots=True,
        )
        
        # ì£¼ìš” ë©”íŠ¸ë¦­ ì¶œë ¥
        OpLog(f"mAP50: {metrics.box.map50:.4f}", bLines=False)
        OpLog(f"mAP50-95: {metrics.box.map:.4f}", bLines=False)
        OpLog(f"Precision: {metrics.box.mp:.4f}", bLines=False)
        OpLog(f"Recall: {metrics.box.mr:.4f}", bLines=False)
        
        return metrics
    
    def predict(self, source, conf=0.25, save=True):
        """
        ì´ë¯¸ì§€ì— ëŒ€í•œ ì˜ˆì¸¡ ìˆ˜í–‰
        
        Args:
            source: ì´ë¯¸ì§€ ê²½ë¡œ, í´ë” ê²½ë¡œ, ë˜ëŠ” ì´ë¯¸ì§€ URL
            conf: ì‹ ë¢°ë„ ì„ê³„ê°’
            save: ê²°ê³¼ ì €ì¥ ì—¬ë¶€
        """
        results = self.model.predict(
            source=source,
            conf=conf,
            save=save,
            project=os.path.join(BASE_DIR, "yolo_results"),
            name=f"yolov8{self.model_size}_predict",
            exist_ok=True,
        )
        
        return results
    
    def load_yolo_model(self, model_path):
        """YOLOv8 ëª¨ë¸ ë¡œë“œ"""
        if not os.path.exists(model_path):
            OpLog(f"ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model_path}", bLines=True)
            return False
        
        self.model = YOLO(model_path)
        OpLog(f"YOLOv8 ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {model_path}", bLines=True)
        return True
    
    def save_yolo_model(self, save_path=None):
        """YOLOv8 ëª¨ë¸ ì €ì¥"""
        if save_path is None:
            save_path = os.path.join(MODEL_FILES, f"yolov8{self.model_size}_final.pt")
        
        makedirs(os.path.dirname(save_path))
        
        # YOLOv8 ëª¨ë¸ ë‚´ë³´ë‚´ê¸°
        self.model.export(format='torchscript', dynamic=False)
        
        OpLog(f"YOLOv8 ëª¨ë¸ ì €ì¥ë¨: {save_path}", bLines=True)
        return save_path
    
    def plot_results(self):
        """í•™ìŠµ ê²°ê³¼ ì‹œê°í™”"""
        results_dir = os.path.join(BASE_DIR, "yolo_results", f"yolov8{self.model_size}_train")
        results_file = os.path.join(results_dir, "results.png")
        
        if os.path.exists(results_file):
            OpLog(f"í•™ìŠµ ê²°ê³¼ ê·¸ë˜í”„: {results_file}", bLines=False)
        else:
            OpLog("í•™ìŠµ ê²°ê³¼ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", bLines=False)
        plt.close()